{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure notebook, torch, and file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nb_util import data_path, device\n",
    "\n",
    "model_name = 'celeba-small-glow'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import flow.data as data\n",
    "\n",
    "batch_size_manifold = 32\n",
    "batch_size_density = 32\n",
    "channels = 3\n",
    "height = 64\n",
    "width = 64\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_data = data.CelebA(root=data_path, split='train', transform=transform)\n",
    "test_data = data.CelebA(root=data_path, split='test', transform=transform)\n",
    "\n",
    "manifold_loader = DataLoader(train_data, batch_size=batch_size_manifold, shuffle=True, num_workers=30)\n",
    "density_loader = DataLoader(train_data, batch_size=batch_size_density, shuffle=True, num_workers=30)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size_manifold, shuffle=True, num_workers=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manifold model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct manifold-learning component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import flow.components as comp\n",
    "\n",
    "manifold_model = comp.Sequential(\n",
    "    comp.GlowNet(channels, k=3, l=2, additive_coupling=True, hidden_size=8, out_shape=(8, 8)),\n",
    "    comp.Invertible1x1Conv(channels*64),\n",
    "    comp.Pad(channels*64, channels*8),\n",
    ")\n",
    "manifold_model.to(device)\n",
    "\n",
    "# Check for runtime errors and initialize weights with first batch\n",
    "num_recons = 8\n",
    "sample_x = next(iter(manifold_loader))[0].to(device)[:num_recons]\n",
    "with torch.no_grad():\n",
    "    sample_mid_latent = manifold_model.initialize(sample_x)\n",
    "\n",
    "m = sample_mid_latent.numel() // num_recons # Dimension of latent space\n",
    "with torch.no_grad():\n",
    "    manifold_model.data_to_latent(sample_x, m)\n",
    "    manifold_model.latent_to_data(sample_mid_latent, m)\n",
    "    \n",
    "f'Parameters: {sum(w.numel() for w in manifold_model.parameters() if w.requires_grad)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the learned manifold using reconstruction loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as opt\n",
    "from nb_util import compare_batches\n",
    "\n",
    "epochs = 10\n",
    "manifold_opt = opt.Adam(manifold_model.parameters(), lr=0.0001)\n",
    "manifold_model.train()\n",
    "\n",
    "sample_mid_latent = manifold_model(sample_x, inverse=True)\n",
    "sample_recons =  manifold_model(sample_mid_latent)\n",
    "fig, display_id = compare_batches(sample_x, sample_recons)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch, (image, _) in enumerate(manifold_loader):\n",
    "        image = image.to(device)\n",
    "\n",
    "        # Compute reconstruction error\n",
    "        manifold_opt.zero_grad()\n",
    "        \n",
    "        mid_latent = manifold_model(image, inverse=True)\n",
    "        reconstruction = manifold_model(mid_latent)\n",
    "        reconstruction_error = torch.mean((image - reconstruction)**2)\n",
    "\n",
    "        # Training step\n",
    "        loss = reconstruction_error\n",
    "        loss.backward()\n",
    "        manifold_opt.step()\n",
    "\n",
    "        # Display results\n",
    "        print(f'[E{epoch} B{batch}] | Reconstruction: {reconstruction_error:6.5f}', end='\\r')\n",
    "        if batch % 20 == 0:\n",
    "            with torch.no_grad():\n",
    "                sample_mid_latent = manifold_model(sample_x, inverse=True)\n",
    "                sample_recons =  manifold_model(sample_mid_latent)\n",
    "            compare_batches(sample_x, sample_recons, fig, display_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute reconstruction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_errors = []\n",
    "\n",
    "for image, _ in test_loader:\n",
    "    image = image.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        mid_latent = manifold_model(image, inverse=True)\n",
    "        reconstruction = manifold_model(mid_latent)\n",
    "        reconstruction_error = torch.mean((image - reconstruction)**2).detach()\n",
    "\n",
    "    rec_errors.append(reconstruction_error)\n",
    "\n",
    "f'Reconstruction error: {np.mean([float(err) for err in rec_errors])}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save manifold model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(manifold_model.state_dict(), f'models/{model_name}-manifold.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct density-learning component and concatenate the two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_model = comp.Sequential(\n",
    "    comp.GlowNet(channels*8, k=3, l=3),\n",
    ")\n",
    "density_model.to(device)\n",
    "\n",
    "# Initialize the weights of the density model and check for errors\n",
    "with torch.no_grad():\n",
    "    sample_mid_latent = manifold_model(sample_x, inverse=True)\n",
    "    sample_z = density_model.initialize(sample_mid_latent)\n",
    "    density_model.data_to_latent(sample_mid_latent, m)\n",
    "    density_model.latent_to_data(sample_z, m)\n",
    "\n",
    "f'Parameters: {sum(w.numel() for w in density_model.parameters() if w.requires_grad)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample some latents to show during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 16 samples with reduced temperature for visualization\n",
    "temp = 0.75\n",
    "num_samples = 16\n",
    "\n",
    "with torch.no_grad():\n",
    "    latent_shape = density_model(sample_mid_latent, inverse=True).shape[1:]\n",
    "\n",
    "latent_samples = torch.normal(mean=torch.zeros(num_samples, *latent_shape), \n",
    "                              std=torch.ones(num_samples, *latent_shape)*temp)\n",
    "latent_samples = latent_samples.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the density with log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as f\n",
    "from nb_util import display_batch, update_displayed_batch\n",
    "\n",
    "epochs = 300\n",
    "density_opt = opt.Adam(density_model.parameters(), lr=0.00001)             \n",
    "\n",
    "const = -(m/2) * np.log(2*np.pi) # Constant for log likelihood\n",
    "\n",
    "manifold_model.eval()\n",
    "density_model.train()\n",
    "mid_latent = density_model(latent_samples)\n",
    "gen_samples = manifold_model(mid_latent)\n",
    "fig, display_id = display_batch(gen_samples)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch, (image, _) in enumerate(density_loader):\n",
    "        image = image.to(device)\n",
    "        density_opt.zero_grad()\n",
    "\n",
    "        # Compute log likelihood\n",
    "        with torch.no_grad():\n",
    "            mid_latent, _ = manifold_model.data_to_latent(image, m)\n",
    "        z, density_log_det = density_model.data_to_latent(mid_latent, m)\n",
    "        log_pz = const - torch.sum(z**2, axis=1)/2\n",
    "        half_log_det = density_log_det\n",
    "        log_likelihood = torch.mean(log_pz + half_log_det)\n",
    "\n",
    "        # Training step\n",
    "        loss = -log_likelihood\n",
    "        loss.backward()\n",
    "        density_opt.step()\n",
    "\n",
    "        # Display results\n",
    "        print(f'[E{epoch} B{batch}] | Log-likelihood: {log_likelihood:6.2f} '\n",
    "              f'| Logp(z): {torch.mean(log_pz):6.2f} '\n",
    "              f'| Log det: {torch.mean(half_log_det):6.2f}', end='\\r')\n",
    "        if batch % 10 == 0:\n",
    "            with torch.no_grad():\n",
    "                mid_latent = density_model(latent_samples)\n",
    "                gen_samples = manifold_model(mid_latent)\n",
    "            update_displayed_batch(gen_samples, fig, display_id)\n",
    "            \n",
    "    torch.save(density_model.state_dict(), f'models/{model_name}-density-e{epoch}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as opt\n",
    "\n",
    "test_data = data.CelebA(root=data_path, split='test', transform=transform)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=True, num_workers=30)\n",
    "\n",
    "\n",
    "likelihoods = []\n",
    "\n",
    "for image, _ in test_loader:\n",
    "    image = image.to(device)\n",
    "\n",
    "    # Compute log likelihood\n",
    "    with torch.no_grad():\n",
    "        mid_latent, _ = manifold_model.data_to_latent(image, m)\n",
    "        _, manifold_log_det = manifold_model.latent_to_data(mid_latent, m)\n",
    "        z, density_log_det = density_model.data_to_latent(mid_latent, m)\n",
    "        log_pz = const - torch.sum(z**2, axis=1)/2\n",
    "        half_log_det = manifold_log_det + density_log_det\n",
    "        log_likelihood = torch.mean(log_pz + half_log_det)\n",
    "        \n",
    "    likelihoods.append(log_likelihood)\n",
    "    \n",
    "np.mean([float(lik) for lik in likelihoods])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    mid_latent = density_model(latent_samples)\n",
    "    gen_samples = manifold_model(mid_latent)\n",
    "fig, display_id = display_batch(gen_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nb_util import generate_image_samples\n",
    "\n",
    "eval_epoch = 100\n",
    "manifold_model.load_state_dict(torch.load(f'models/{model_name}-manifold.pt'))\n",
    "density_model.load_state_dict(torch.load(f'models/{model_name}-density-e{eval_epoch}.pt'))\n",
    "full_model = manifold_model + density_model\n",
    "\n",
    "generate_image_samples(\n",
    "    30000, full_model, model_name + '2', latent_shape=latent_shape, batch_size=16, temp=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls data/celeba/list_eval_partition.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/celeba/list_eval_partition.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['partition'] == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check stats for all the parameters. Check for invertibility (the model should be left invertible but not necessarily right invertible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = full_model\n",
    "\n",
    "with torch.no_grad():\n",
    "    for component in model.components:\n",
    "        print(component.__class__.__name__)\n",
    "\n",
    "        for parameter in component.parameters():\n",
    "            if parameter.requires_grad:\n",
    "                print(f'\\tParam shape: {parameter.shape}')\n",
    "                print(f'\\t\\tmin:  {torch.min(parameter):6.3f}')\n",
    "                print(f'\\t\\tmax:  {torch.max(parameter):6.3f}')\n",
    "                print(f'\\t\\tmean:  {torch.mean(parameter):6.3f}')\n",
    "                print(f'\\t\\tnorm: {torch.linalg.norm(parameter):6.3f}')\n",
    "\n",
    "\n",
    "    print('Invertibility check')\n",
    "    right_invertibility = torch.max(model(model(sample_x, inverse=True)) - sample_x)\n",
    "    print(f'\\tRight invertibility: {right_invertibility:6.5f}')\n",
    "\n",
    "    left_invertibility = torch.max(model(model(model(sample_x, inverse=True)), inverse=True) \n",
    "                                   - model(sample_x, inverse=True))\n",
    "    print(f'\\tLeft invertibility: {left_invertibility:6.5f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
