{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure notebook, torch, and file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nb_util import data_path, device\n",
    "\n",
    "model_name = 'celeba-conformal-glow-joint'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import flow.data as data\n",
    "\n",
    "batch_size = 32\n",
    "channels = 3\n",
    "height = 64\n",
    "width = 64\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_data = data.CelebA(root=data_path, split='train', transform=transform)\n",
    "test_data = data.CelebA(root=data_path, split='test', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=30)\n",
    "cluster_loader = DataLoader(train_data, batch_size=1024, shuffle=True, num_workers=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct manifold-learning component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import flow.components as comp\n",
    "\n",
    "manifold_model = comp.Sequential(\n",
    "    comp.Shift(shape=(channels, height, width)),\n",
    "    comp.Scale(),\n",
    "    \n",
    "    comp.HouseholderConv(channels, kernel_size=2),\n",
    "    comp.Shift(shape=(channels*4, height//2, width//2)),\n",
    "    comp.Scale(),\n",
    "    comp.HouseholderConv(channels*4, kernel_size=1),\n",
    "    comp.Shift(shape=(channels*4, height//2, width//2)),\n",
    "    comp.Scale(),\n",
    "    \n",
    "    comp.ConditionalConv(channels*4),\n",
    "    comp.Shift(shape=(channels*4, height//2, width//2)),\n",
    "    comp.Scale(),\n",
    "    \n",
    "    comp.Pad(channels*4, channels*2),\n",
    "        \n",
    "    comp.HouseholderConv(channels*2, kernel_size=2),\n",
    "    comp.Shift(shape=(channels*8, height//4, width//4)),\n",
    "    comp.Scale(),\n",
    "    comp.HouseholderConv(channels*8, kernel_size=1),\n",
    "    comp.Shift(shape=(channels*8, height//4, width//4)),\n",
    "    comp.Scale(),\n",
    "    \n",
    "    comp.ConditionalConv(channels*8),\n",
    "    comp.Shift(shape=(channels*8, height//4, width//4)),\n",
    "    comp.Scale(),\n",
    "    \n",
    "    comp.Pad(channels*8, channels*4),\n",
    "       \n",
    "    comp.HouseholderConv(channels*4, kernel_size=2),\n",
    "    comp.Shift(shape=(channels*16, height//8, width//8)),\n",
    "    comp.Scale(),\n",
    "    comp.HouseholderConv(channels*16, kernel_size=1),\n",
    "    comp.Shift(shape=(channels*16, height//8, width//8)),\n",
    "    comp.Scale(),\n",
    "    \n",
    "    comp.ConditionalConv(channels*16),\n",
    "    comp.Shift(shape=(channels*16, height//8, width//8)),\n",
    "    comp.Scale(),\n",
    "    \n",
    "    comp.Pad(channels*16, channels*8),\n",
    ")\n",
    "manifold_model.to(device)\n",
    "\n",
    "\n",
    "# Check for runtime errors and initialize weights with first batch\n",
    "num_recons = 4\n",
    "init_x = next(iter(train_loader))[0].to(device)\n",
    "with torch.no_grad():\n",
    "    init_mid_latent = manifold_model.initialize(init_x)\n",
    "    \n",
    "sample_x = init_x[:num_recons] # Store some samples to visualize reconstructions\n",
    "\n",
    "m = init_mid_latent[0].numel() // num_recons # Dimension of latent space\n",
    "with torch.no_grad():\n",
    "    manifold_model.data_to_latent(init_x, m)\n",
    "    manifold_model.latent_to_data(init_mid_latent, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct density-learning component and concatenate the two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_model = comp.Sequential(\n",
    "    comp.GlowNet(channels*8, k=3, l=3),\n",
    ")\n",
    "density_model.to(device)\n",
    "\n",
    "full_model = manifold_model + density_model\n",
    "\n",
    "# Initialize the weights of the density model and check for errors\n",
    "with torch.no_grad():\n",
    "    init_z = density_model.initialize(init_mid_latent)\n",
    "    density_model.data_to_latent(init_mid_latent, m)\n",
    "    density_model.latent_to_data(init_z, m)\n",
    "    \n",
    "f'Parameters: {sum(w.numel() for w in full_model.parameters() if w.requires_grad)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample some latents to show during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 8 samples with reduced temperature for visualization\n",
    "temp = 0.75\n",
    "num_samples = 8\n",
    "\n",
    "with torch.no_grad():\n",
    "    latent_shape = density_model(init_mid_latent, inverse=True).shape[1:]\n",
    "\n",
    "latent_samples = torch.normal(mean=torch.zeros(num_samples, *latent_shape), \n",
    "                              std=torch.ones(num_samples, *latent_shape)*temp)\n",
    "latent_samples = latent_samples.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schedule training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedule():\n",
    "    '''Yields weights for density and reconstruction respectively'''\n",
    "    for _ in range(10):\n",
    "        yield 0, 10000\n",
    "        \n",
    "    # After manifold warmup, re-initialize density model    \n",
    "    with torch.no_grad():\n",
    "        sample_mid_latent = manifold_model(sample_x, inverse=True)\n",
    "        sample_z = density_model.initialize(sample_mid_latent)\n",
    "        \n",
    "    while True:\n",
    "        yield 0.001, 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the density with log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as opt\n",
    "from nb_util import compare_batches, display_batch, update_displayed_batch\n",
    "\n",
    "full_opt = opt.Adam(full_model.parameters(), lr=0.00001)             \n",
    "const = -(m/2) * np.log(2*np.pi) # Constant for log likelihood\n",
    "\n",
    "full_model.train()\n",
    "\n",
    "gen_samples = full_model(latent_samples.to(device))\n",
    "sample_recons =  manifold_model(manifold_model(sample_x, inverse=True))\n",
    "fig1, display_id1 = display_batch(gen_samples)\n",
    "fig2, display_id2 = compare_batches(sample_x, sample_recons)\n",
    "\n",
    "for epoch, (alpha, beta) in enumerate(schedule()):\n",
    "    for batch, (image, _) in enumerate(train_loader):\n",
    "        image = image.to(device)\n",
    "        full_opt.zero_grad()\n",
    "\n",
    "        # Compute reconstruction error\n",
    "        with torch.set_grad_enabled(beta > 0):\n",
    "            mid_latent, _ = manifold_model.data_to_latent(image, m)\n",
    "            _, manifold_log_det = manifold_model.latent_to_data(mid_latent, m)\n",
    "            reconstruction = manifold_model(mid_latent)\n",
    "            reconstruction_error = torch.mean((image - reconstruction)**2)\n",
    "\n",
    "        # Compute log likelihood\n",
    "        with torch.set_grad_enabled(alpha > 0):\n",
    "            z, density_log_det = density_model.data_to_latent(mid_latent, m)\n",
    "            log_pz = const - torch.sum(z**2, axis=1)/2\n",
    "            half_log_det = manifold_log_det + density_log_det\n",
    "            log_likelihood = torch.mean(log_pz + half_log_det)\n",
    "\n",
    "        # Training step\n",
    "        loss = - alpha*log_likelihood + beta*reconstruction_error\n",
    "        loss.backward()\n",
    "        full_opt.step()\n",
    "\n",
    "        # Display results\n",
    "        print(f'[E{epoch} B{batch}] | '\n",
    "              f'loss: {loss: 6.2f} '\n",
    "              f'| LL: {log_likelihood:6.2f} '\n",
    "              f'| logp(z): {torch.mean(log_pz):6.2f} '\n",
    "              f'| logdet: {torch.mean(half_log_det):6.2f}'\n",
    "              f'| manifold logdet: {torch.mean(manifold_log_det):6.2f}'\n",
    "              f'| density logdet: {torch.mean(density_log_det):6.2f}'\n",
    "              f'| recon: {reconstruction_error:6.5f}', end='\\r')\n",
    "        if batch % 10 == 0:\n",
    "            with torch.no_grad():\n",
    "                gen_samples = full_model(latent_samples)\n",
    "                sample_recons =  manifold_model(manifold_model(sample_x, inverse=True))\n",
    "            update_displayed_batch(gen_samples, fig1, display_id1)\n",
    "            compare_batches(sample_x, sample_recons, fig2, display_id2)\n",
    "            \n",
    "    torch.save(full_model.state_dict(), f'models/{model_name}-e{epoch}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute reconstruction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_errors = []\n",
    "\n",
    "for image, _ in test_loader:\n",
    "    image = image.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        mid_latent = manifold_model(image, inverse=True)\n",
    "        reconstruction = manifold_model(mid_latent)\n",
    "        reconstruction_error = torch.mean((image - reconstruction)**2).detach()\n",
    "\n",
    "    rec_errors.append(reconstruction_error)\n",
    "\n",
    "f'Reconstruction error: {np.mean([float(err) for err in rec_errors])}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nb_util import generate_image_samples\n",
    "\n",
    "eval_epoch = 20\n",
    "full_model.load_state_dict(torch.load(f'models/{model_name}-e{eval_epoch}.pt'))\n",
    "\n",
    "generate_image_samples(\n",
    "    100, full_model, model_name, latent_shape=latent_shape, batch_size=16, temp=temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check stats for all the parameters. Check for invertibility (the model should be left invertible but not necessarily right invertible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = full_model\n",
    "\n",
    "with torch.no_grad():\n",
    "    for component in model.components:\n",
    "        print(component.__class__.__name__)\n",
    "\n",
    "        for parameter in component.parameters():\n",
    "            if parameter.requires_grad:\n",
    "                print(f'\\tParam shape: {parameter.shape}')\n",
    "                print(f'\\t\\tmin:  {torch.min(parameter):6.3f}')\n",
    "                print(f'\\t\\tmax:  {torch.max(parameter):6.3f}')\n",
    "                print(f'\\t\\tmean:  {torch.mean(parameter):6.3f}')\n",
    "                print(f'\\t\\tnorm: {torch.linalg.norm(parameter):6.3f}')\n",
    "\n",
    "\n",
    "    print('Invertibility check')\n",
    "    right_invertibility = torch.max(model(model(sample_x, inverse=True)) - sample_x)\n",
    "    print(f'\\tRight invertibility: {right_invertibility:6.5f}')\n",
    "\n",
    "    left_invertibility = torch.max(model(model(model(sample_x, inverse=True)), inverse=True) \n",
    "                                   - model(sample_x, inverse=True))\n",
    "    print(f'\\tLeft invertibility: {left_invertibility:6.5f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cef",
   "language": "python",
   "name": "cef"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
